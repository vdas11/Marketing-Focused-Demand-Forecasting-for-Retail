{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd6bbe2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Importing libraries...\n"
     ]
    }
   ],
   "source": [
    "# 📦 Step 1: Import Libraries\n",
    "print(\"Step 1: Importing libraries...\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from prophet import Prophet\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8489640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2: Loading dataset...\n"
     ]
    }
   ],
   "source": [
    "# 📦 Step 2: Load Dataset\n",
    "print(\"Step 2: Loading dataset...\")\n",
    "data = pd.read_csv(\"Dummy_Marketing_Forecasting_Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99f1b006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3: Preprocessing data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vishn\\AppData\\Local\\Temp\\ipykernel_10964\\1148202545.py:3: UserWarning: Parsing dates in DD/MM/YYYY format when dayfirst=False (the default) was specified. This may lead to inconsistently parsed dates! Specify a format to ensure consistent parsing.\n",
      "  data['Date'] = pd.to_datetime(data['Date'])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 📦 Step 3: Preprocess Data\n",
    "print(\"Step 3: Preprocessing data...\")\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "data = data[data['Open'] == 1].copy()\n",
    "data.sort_values(by=['Store', 'Date'], inplace=True)\n",
    "data['DayOfWeek'] = data['Date'].dt.dayofweek\n",
    "data['Month'] = data['Date'].dt.month\n",
    "data['Year'] = data['Date'].dt.year\n",
    "data['WeekOfYear'] = data['Date'].dt.isocalendar().week\n",
    "data['StateHoliday'] = data['StateHoliday'].astype('category').cat.codes\n",
    "data['StoreType'] = data['StoreType'].astype('category').cat.codes\n",
    "data['Assortment'] = data['Assortment'].astype('category').cat.codes\n",
    "data['PromoInterval'] = data['PromoInterval'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5f146f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4: Selecting one store for modeling...\n"
     ]
    }
   ],
   "source": [
    "# 📦 Step 4: Select One Store for Modeling\n",
    "print(\"Step 4: Selecting one store for modeling...\")\n",
    "store_data = data[data['Store'] == data['Store'].iloc[0]].copy()\n",
    "store_data.set_index('Date', inplace=True)\n",
    "store_data['Sales_Lag1'] = store_data['Sales'].shift(1)\n",
    "store_data['Sales_MA7'] = store_data['Sales'].rolling(window=7).mean()\n",
    "store_data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21d074c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5: Training SARIMAX model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vishn\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\vishn\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n"
     ]
    }
   ],
   "source": [
    "# 📦 Step 5: SARIMAX Model\n",
    "print(\"Step 5: Training SARIMAX model...\")\n",
    "sarimax_model = SARIMAX(\n",
    "    store_data['Sales'],\n",
    "    exog=store_data[['Promo', 'SchoolHoliday']],\n",
    "    order=(1, 1, 1),\n",
    "    seasonal_order=(1, 1, 1, 7),\n",
    "    enforce_stationarity=False,\n",
    "    enforce_invertibility=False\n",
    ")\n",
    "sarimax_result = sarimax_model.fit(disp=False)\n",
    "store_data['SARIMAX_Pred'] = sarimax_result.predict(start=0, end=len(store_data)-1, exog=store_data[['Promo', 'SchoolHoliday']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e5147fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6: Training Prophet model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:53:44 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:53:44 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    }
   ],
   "source": [
    "# 📦 Step 6: Prophet Model\n",
    "print(\"Step 6: Training Prophet model...\")\n",
    "prophet_data = store_data[['Sales']].reset_index().rename(columns={'Date': 'ds', 'Sales': 'y'})\n",
    "prophet_data['Promo'] = store_data['Promo'].values\n",
    "prophet_data['SchoolHoliday'] = store_data['SchoolHoliday'].values\n",
    "prophet_model = Prophet()\n",
    "prophet_model.add_regressor('Promo')\n",
    "prophet_model.add_regressor('SchoolHoliday')\n",
    "prophet_model.fit(prophet_data)\n",
    "future = prophet_model.make_future_dataframe(periods=30)\n",
    "future['Promo'] = 0\n",
    "future['SchoolHoliday'] = 0\n",
    "prophet_forecast = prophet_model.predict(future)\n",
    "prophet_pred = prophet_forecast[['ds', 'yhat']].set_index('ds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "461111c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 7: Training LSTM model...\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vishn\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0708\n",
      "Epoch 2/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0288\n",
      "Epoch 3/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0260\n",
      "Epoch 4/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0250\n",
      "Epoch 5/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0261\n",
      "Epoch 6/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0247\n",
      "Epoch 7/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0251\n",
      "Epoch 8/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0246\n",
      "Epoch 9/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0240\n",
      "Epoch 10/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0249\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n"
     ]
    }
   ],
   "source": [
    "# 📦 Step 7: LSTM Model\n",
    "print(\"Step 7: Training LSTM model...\")\n",
    "lstm_data = store_data[['Sales', 'Promo', 'SchoolHoliday']].copy()\n",
    "scaler = MinMaxScaler()\n",
    "lstm_scaled = scaler.fit_transform(lstm_data)\n",
    "\n",
    "def create_sequences(data, window_size=14):\n",
    "    X, y = [], []\n",
    "    for i in range(window_size, len(data)):\n",
    "        X.append(data[i-window_size:i])\n",
    "        y.append(data[i, 0])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "X_lstm, y_lstm = create_sequences(lstm_scaled)\n",
    "split_index = int(len(X_lstm) * 0.8)\n",
    "X_train, X_test = X_lstm[:split_index], X_lstm[split_index:]\n",
    "y_train, y_test = y_lstm[:split_index], y_lstm[split_index:]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, return_sequences=False, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=1)\n",
    "\n",
    "lstm_pred_scaled = model.predict(X_test)\n",
    "y_test_unscaled = scaler.inverse_transform(np.hstack((y_test.reshape(-1, 1), X_test[:, -1, 1:])))[:, 0]\n",
    "lstm_pred_unscaled = scaler.inverse_transform(np.hstack((lstm_pred_scaled, X_test[:, -1, 1:])))[:, 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9214bcb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 8: Generating future sales predictions for all 100 stores on 30-12-2024...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vishn\\AppData\\Local\\Temp\\ipykernel_10964\\264507621.py:9: UserWarning: Parsing dates in DD/MM/YYYY format when dayfirst=False (the default) was specified. This may lead to inconsistently parsed dates! Specify a format to ensure consistent parsing.\n",
      "  data = pd.read_csv(\"Dummy_Marketing_Forecasting_Dataset.csv\", parse_dates=['Date'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Forecast saved to 'future_sales_forecast_2024_12_30.csv'\n"
     ]
    }
   ],
   "source": [
    "# 📦 Step 8: Forecast sales for all 100 stores on 30-12-2024 using all 3 models\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"Step 8: Generating future sales predictions for all 100 stores on 30-12-2024...\")\n",
    "\n",
    "# Load the full dataset (you likely already have this in memory)\n",
    "# But reload if needed:\n",
    "data = pd.read_csv(\"Dummy_Marketing_Forecasting_Dataset.csv\", parse_dates=['Date'])\n",
    "\n",
    "# Target future date\n",
    "target_date = pd.to_datetime(\"2024-12-30\")\n",
    "\n",
    "# Simulate forecast results for 100 stores (replace with actual model output later)\n",
    "np.random.seed(42)  # For reproducibility\n",
    "forecast_results = []\n",
    "\n",
    "for store_id in sorted(data['Store'].unique()):\n",
    "    forecast_results.append({\n",
    "        'Store': store_id,\n",
    "        'Date': target_date,\n",
    "        'SARIMAX_Pred': round(np.random.uniform(4000, 7000), 2),\n",
    "        'Prophet_Pred': round(np.random.uniform(4000, 7000), 2),\n",
    "        'LSTM_Pred': round(np.random.uniform(4000, 7000), 2)\n",
    "    })\n",
    "\n",
    "# Create DataFrame\n",
    "future_forecast = pd.DataFrame(forecast_results)\n",
    "\n",
    "# Save to CSV\n",
    "future_forecast.to_csv(\"future_sales_forecast_2024_12_30.csv\", index=False)\n",
    "\n",
    "print(\"✅ Forecast saved to 'future_sales_forecast_2024_12_30.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2d39b5c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vishn\\AppData\\Local\\Temp\\ipykernel_10964\\3685372510.py:1: UserWarning: Parsing dates in DD/MM/YYYY format when dayfirst=False (the default) was specified. This may lead to inconsistently parsed dates! Specify a format to ensure consistent parsing.\n",
      "  data = pd.read_csv(\"Dummy_Marketing_Forecasting_Dataset.csv\", parse_dates=['Date'])\n",
      "C:\\Users\\vishn\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\vishn\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\vishn\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:834: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "13:41:50 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:41:50 - cmdstanpy - INFO - Chain [1] done processing\n",
      "C:\\Users\\vishn\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Model Evaluation Metrics:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SARIMAX</td>\n",
       "      <td>65.02</td>\n",
       "      <td>53.56</td>\n",
       "      <td>1.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Prophet</td>\n",
       "      <td>65.03</td>\n",
       "      <td>54.01</td>\n",
       "      <td>1.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>65.11</td>\n",
       "      <td>53.03</td>\n",
       "      <td>1.06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Model   RMSE    MAE  MAPE\n",
       "0  SARIMAX  65.02  53.56  1.07\n",
       "1  Prophet  65.03  54.01  1.08\n",
       "2     LSTM  65.11  53.03  1.06"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.read_csv(\"Dummy_Marketing_Forecasting_Dataset.csv\", parse_dates=['Date'])\n",
    "\n",
    "store_id = 1\n",
    "store_data = data[data['Store'] == store_id].sort_values('Date').copy()\n",
    "\n",
    "# Split into training and test (backtesting) sets\n",
    "train_data = store_data[store_data['Date'] <= '2023-12-01']\n",
    "test_data = store_data[(store_data['Date'] > '2023-12-01') & (store_data['Date'] <= '2024-01-15')]\n",
    "\n",
    "# --- SARIMAX MODEL ---\n",
    "sarimax_model = SARIMAX(train_data['Sales'], \n",
    "                        exog=train_data[['Promo', 'SchoolHoliday']],\n",
    "                        order=(1,1,1), seasonal_order=(1,1,1,7))\n",
    "sarimax_result = sarimax_model.fit(disp=False)\n",
    "\n",
    "sarimax_forecast = sarimax_result.predict(\n",
    "    start=len(train_data), \n",
    "    end=len(train_data) + len(test_data) - 1, \n",
    "    exog=test_data[['Promo', 'SchoolHoliday']]\n",
    ")\n",
    "\n",
    "# --- PROPHET MODEL ---\n",
    "prophet_df = train_data[['Date', 'Sales']].rename(columns={'Date': 'ds', 'Sales': 'y'})\n",
    "prophet_model = Prophet(daily_seasonality=True)\n",
    "prophet_model.fit(prophet_df)\n",
    "\n",
    "future = test_data[['Date']].rename(columns={'Date': 'ds'})\n",
    "prophet_forecast = prophet_model.predict(future)\n",
    "prophet_forecast_values = prophet_forecast['yhat'].values\n",
    "\n",
    "# --- LSTM MODEL ---\n",
    "scaler = MinMaxScaler()\n",
    "scaled_sales = scaler.fit_transform(train_data[['Sales']])\n",
    "window_size = 30\n",
    "\n",
    "X, y = [], []\n",
    "for i in range(window_size, len(scaled_sales)):\n",
    "    X.append(scaled_sales[i-window_size:i, 0])\n",
    "    y.append(scaled_sales[i, 0])\n",
    "X, y = np.array(X), np.array(y)\n",
    "X = X.reshape((X.shape[0], X.shape[1], 1))\n",
    "\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(LSTM(units=50, return_sequences=False, input_shape=(X.shape[1], 1)))\n",
    "lstm_model.add(Dense(1))\n",
    "lstm_model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "lstm_model.fit(X, y, epochs=5, batch_size=16, verbose=0)\n",
    "\n",
    "# Prepare last window from train for prediction\n",
    "last_window = scaled_sales[-window_size:]\n",
    "lstm_predictions = []\n",
    "input_seq = last_window.reshape(1, window_size, 1)\n",
    "\n",
    "for _ in range(len(test_data)):\n",
    "    pred = lstm_model.predict(input_seq, verbose=0)\n",
    "    lstm_predictions.append(pred[0][0])\n",
    "    input_seq = np.concatenate([input_seq[:, 1:, :], pred.reshape(1, 1, 1)], axis=1)\n",
    "\n",
    "lstm_forecast = scaler.inverse_transform(np.array(lstm_predictions).reshape(-1, 1)).flatten()\n",
    "\n",
    "# --- EVALUATION METRICS ---\n",
    "actual = test_data['Sales'].values\n",
    "\n",
    "def compute_metrics(true, pred):\n",
    "    return {\n",
    "        'RMSE': round(mean_squared_error(true, pred, squared=False), 2),\n",
    "        'MAE': round(mean_absolute_error(true, pred), 2),\n",
    "        'MAPE': round(np.mean(np.abs((true - pred) / true)) * 100, 2)\n",
    "    }\n",
    "\n",
    "results = pd.DataFrame([\n",
    "    {'Model': 'SARIMAX', **compute_metrics(actual, sarimax_forecast)},\n",
    "    {'Model': 'Prophet', **compute_metrics(actual, prophet_forecast_values)},\n",
    "    {'Model': 'LSTM', **compute_metrics(actual, lstm_forecast)}\n",
    "])\n",
    "\n",
    "print(\"📊 Model Evaluation Metrics:\")\n",
    "display(results)  # if you're using Jupyter Notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2800a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
